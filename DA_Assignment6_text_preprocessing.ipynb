{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAAhgwIsD9FR",
        "outputId": "e6b308ef-65c6-4929-8a14-8846c5329689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "#import modules\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step2 initi. text\n",
        "txt=\"Tokenization is the first step in text analytics. The process of breaking down a text paragraph into smaller chunks such as words or sentences is alled Tokenization.\""
      ],
      "metadata": {
        "id": "YVKqq468GOzW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Perform Tokenization\n",
        "\n",
        "#Sentence Tokenization\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "tokenized_text =sent_tokenize(txt)\n",
        "\n",
        "print (tokenized_text)\n",
        "\n",
        "#Word Tokenization\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokenized_word=word_tokenize(txt)\n",
        "\n",
        "print (tokenized_word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1loVafn8G_co",
        "outputId": "1f46730c-e393-443f-9412-ef878439674d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tokenization is the first step in text analytics.', 'The process of breaking down a text paragraph into smaller chunks such as words or sentences is alled Tokenization.']\n",
            "['Tokenization', 'is', 'the', 'first', 'step', 'in', 'text', 'analytics', '.', 'The', 'process', 'of', 'breaking', 'down', 'a', 'text', 'paragraph', 'into', 'smaller', 'chunks', 'such', 'as', 'words', 'or', 'sentences', 'is', 'alled', 'Tokenization', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4: Removing Punctuations and Stop Word\n",
        "\n",
        "# print stop words of English\n",
        "from nltk.corpus import stopwords\n",
        "stop_words=set(stopwords.words(\"english\"))\n",
        "print(stop_words)\n",
        "\n",
        "text= \"How to remove stop words with NLTK library in Python?\"\n",
        "import re\n",
        "text= re.sub('[^a-zA-Z]', ' ',text)\n",
        "\n",
        "tokens = word_tokenize(text.lower())\n",
        "filtered_text=[]\n",
        "\n",
        "for w in tokens:\n",
        "  if w not in stop_words:\n",
        "    filtered_text.append(w)\n",
        "\n",
        "print(\"Tokenized Sentence:\", tokens)\n",
        "\n",
        "print(\"Filterd Sentence:\", filtered_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoIG0fvjHicG",
        "outputId": "193cbfed-85fc-4c40-80e8-f8e6a2594854"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'what', 'yours', \"aren't\", 'whom', 'an', 'mightn', \"hasn't\", 'am', 'ain', 'had', 'nor', 'her', 'each', 'just', 'by', \"haven't\", 'here', 'as', 'too', 'those', 'me', 'itself', 'after', 'couldn', 's', 'a', 'he', 'against', 'shouldn', 're', 'during', 'until', 'them', 'yourselves', 'such', 'do', 't', \"don't\", 'where', \"she's\", 'myself', 'she', 'between', 'aren', 'their', 'was', \"couldn't\", 'all', 'there', 'few', 'did', \"wouldn't\", 'through', 'while', 'about', 'over', 'from', 'm', 'you', 'again', 'haven', 'd', 'll', 'when', 'doesn', 'are', 'not', 'hasn', 'how', \"you're\", 'his', 'any', 'below', 'does', 'so', \"won't\", 'if', 'yourself', 'but', \"doesn't\", \"isn't\", 'didn', 'its', 'this', 'other', \"that'll\", 'once', 'down', 'up', 'only', \"it's\", 'some', 'weren', \"you'll\", 'into', 'ours', 'most', 'y', 'now', \"needn't\", 'shan', 'hadn', 'or', 'which', 'be', \"didn't\", \"you'd\", 'is', 've', 'him', 'under', 'won', 'it', 'then', 'own', \"mustn't\", 'further', 'more', 'who', 'and', 'why', \"mightn't\", \"shouldn't\", 'himself', 'o', \"weren't\", 'before', 'isn', 'out', 'will', 'i', 'mustn', \"shan't\", 'needn', 'they', 'that', 'herself', 'my', 'above', 'wouldn', 'ourselves', 'have', 'having', 'hers', 'themselves', 'ma', 'to', \"wasn't\", 'at', 'for', \"hadn't\", 'doing', \"you've\", 'theirs', 'were', 'of', 'same', 'wasn', 'off', 'our', 'than', 'don', 'your', 'in', 'no', 'very', 'because', 'been', 'should', \"should've\", 'with', 'these', 'being', 'has', 'can', 'the', 'both', 'on', 'we'}\n",
            "Tokenized Sentence: ['how', 'to', 'remove', 'stop', 'words', 'with', 'nltk', 'library', 'in', 'python']\n",
            "Filterd Sentence: ['remove', 'stop', 'words', 'nltk', 'library', 'python']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#perform stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "e_words= [\"wait\", \"waiting\", \"waited\", \"waits\"] #example words\n",
        "ps =PorterStemmer()\n",
        "for w in e_words:\n",
        "    rootWord=ps.stem(w)\n",
        "    print(rootWord)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEQE2YvcJrls",
        "outputId": "049960cf-c44b-49e1-c5d0-ef1b0c58365f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wait\n",
            "wait\n",
            "wait\n",
            "wait\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#perform lemmatization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "text = \"studies studying cries cry\"\n",
        "tokenization = nltk.word_tokenize(text)\n",
        "for w in tokenization:\n",
        "  print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEDZk4w-KjAU",
        "outputId": "3dc1de88-d1ad-49e4-81a4-1b2044f7e902"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemma for studies is study\n",
            "Lemma for studying is studying\n",
            "Lemma for cries is cry\n",
            "Lemma for cry is cry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemma for studies is study: This line shows that the word \"studies\" has been correctly lemmatized to its base form \"study\". The lemmatizer recognized that \"studies\" is a plural form of the noun \"study\" and reduced it to its singular form.\n",
        "\n",
        "Lemma for studying is studying: This line shows that the word \"studying\" remains unchanged after lemmatization. This is because by default, the WordNetLemmatizer assumes words are nouns. To correctly lemmatize verbs, adjectives, or adverbs, you need to specify the part-of-speech (POS) tag using the pos argument in the lemmatize() method.\n",
        "\n",
        "Lemma for cries is cry: This line shows that the word \"cries\" has been correctly lemmatized to its base form \"cry\". The lemmatizer recognized that \"cries\" is a verb form and reduced it to its base form.\n",
        "\n",
        "Lemma for cry is cry: This line shows that the word \"cry\" remains unchanged after lemmatization. This is because it is already in its base form.\n",
        "\n",
        "Lemmatization in Text:\n",
        "\n",
        "In Natural Language Processing (NLP), lemmatization is the process of reducing a word to its base or dictionary form, known as its lemma. This is done by considering the word's context and using morphological analysis to determine its true meaning.\n",
        "\n",
        "Key points about lemmatization:\n",
        "\n",
        "Accuracy: Lemmatization is generally more accurate than stemming, which simply chops off prefixes and suffixes.\n",
        "Context: Lemmatization takes into account the context of the word to determine its lemma.\n",
        "Morphological Analysis: It uses morphological analysis, which involves examining the structure and form of words, to identify the lemma.\n",
        "WordNet: The WordNetLemmatizer in NLTK relies on WordNet, a lexical database that provides information about word relationships.\n",
        "Benefits of lemmatization:\n",
        "\n",
        "Improved Text Analysis: By reducing words to their base forms, lemmatization helps in improving the accuracy of text analysis tasks such as sentiment analysis, topic modeling, and information retrieval.\n",
        "Reduced Dimensionality: Lemmatization can reduce the number of unique words in a text, making it easier to process and analyze.\n",
        "Enhanced NLP Models: Lemmatized text can be used to train more effective NLP models, as it provides a more consistent representation of words.\n",
        "In essence, lemmatization is a valuable technique for normalizing text data by converting words to their base forms, which ultimately improves the quality and efficiency of NLP tasks. I hope this explanation further clarifies the output and the concept of lemmatization in text. Feel free to ask any more questions you might have."
      ],
      "metadata": {
        "id": "OP2phfo3ML_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#apply pos tagging to text\n",
        "from nltk.tokenize import word_tokenize\n",
        "data = \"The pink sweater fits her perfectly\"\n",
        "words = word_tokenize(data)\n",
        "for w in words:\n",
        "  print(nltk.pos_tag([w]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx6R9-x2MNcR",
        "outputId": "24d3919d-71f1-4ad9-ed26-24c6840f7366"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT')]\n",
            "[('pink', 'NN')]\n",
            "[('sweater', 'NN')]\n",
            "[('fits', 'NNS')]\n",
            "[('her', 'PRP$')]\n",
            "[('perfectly', 'RB')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gpt expl.\n",
        "POS Tagging, or Part-of-Speech Tagging, is the process of assigning grammatical tags (also known as POS tags) to each word in a sentence, indicating its part of speech, such as noun, verb, adjective, adverb, etc. It's like labeling each word with its grammatical role in the sentence.\n",
        "\n",
        "Why is POS tagging important?\n",
        "\n",
        "Understanding Sentence Structure: POS tags help in understanding the grammatical structure of a sentence, which is crucial for many NLP tasks.\n",
        "Word Sense Disambiguation: Words can have multiple meanings (e.g., \"bank\" can refer to a financial institution or a river bank). POS tags can help disambiguate word senses by providing context.\n",
        "Text Analysis and NLP Tasks: POS tagging is a fundamental step in many NLP applications, including:\n",
        "Named Entity Recognition (NER): Identifying and classifying named entities like people, organizations, and locations.\n",
        "Sentiment Analysis: Determining the emotional tone of a text.\n",
        "Machine Translation: Translating text from one language to another.\n",
        "Text Summarization: Generating concise summaries of longer texts.\n",
        "Chatbots and Conversational AI: Building systems that can understand and respond to human language.\n",
        "How does POS tagging work?\n",
        "\n",
        "POS tagging involves using algorithms and linguistic rules to analyze the context of a word in a sentence and assign the most likely POS tag. There are different approaches to POS tagging:\n",
        "\n",
        "Rule-based Tagging: Uses hand-crafted grammatical rules to assign tags.\n",
        "Statistical Tagging: Employs statistical models trained on large corpora of text to predict the most probable tag based on word frequencies and context.\n",
        "Deep Learning-based Tagging: Utilizes neural networks to learn complex patterns and relationships between words and their tags.\n",
        "Example:\n",
        "\n",
        "Consider the sentence: \"The cat sat on the mat.\"\n",
        "\n",
        "POS tagging would assign the following tags:\n",
        "\n",
        "The: Determiner (DET)\n",
        "cat: Noun (NN)\n",
        "sat: Verb (VBD)\n",
        "on: Preposition (IN)\n",
        "the: Determiner (DET)\n",
        "mat: Noun (NN)\n",
        "Libraries for POS Tagging:\n",
        "\n",
        "NLTK: Provides various POS taggers, including the pos_tag function and the PerceptronTagger.\n",
        "SpaCy: Offers fast and accurate POS tagging as part of its core NLP pipeline.\n",
        "Stanford CoreNLP: A comprehensive NLP toolkit with a powerful POS tagger.\n",
        "In summary, POS tagging is a crucial technique in NLP for understanding the grammatical structure of text and enabling various NLP applications. It provides valuable information about the role of each word in a sentence, allowing for more sophisticated text analysis and processing. I hope this explanation clarifies POS tagging for you. If you have any further questions, feel free to ask!"
      ],
      "metadata": {
        "id": "oo78Urr8NHBt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "elewBDpfNF23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python algorithm for creating a TF-IDF (Term Frequency-Inverse Document Frequency) representation of documents."
      ],
      "metadata": {
        "id": "8cq1anfsOOI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1: Import necessary libraries.\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "QCim0RXlOPRd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2: Initialize the documents.\n",
        "documentA = 'Jupiter is the largest Planet'\n",
        "documentB = 'Mars is the fourth planet from the Sun'"
      ],
      "metadata": {
        "id": "oo6WMoBgOa-F"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3: Create Bag of Words (BoW) for Document A and B.\n",
        "bagOfWordsA = documentA.split(' ')\n",
        "bagOfWordsB = documentB.split(' ')\n",
        "#Step 4: Create a collection of unique words from Document A and B.\n",
        "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB))"
      ],
      "metadata": {
        "id": "FhpQzKtTOllT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5: Create a dictionary of words and their occurrences for each document.\n",
        "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsA:\n",
        "    numOfWordsA[word] += 1\n",
        "\n",
        "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsB:\n",
        "    numOfWordsB[word] += 1"
      ],
      "metadata": {
        "id": "d3J8SUxcO4Ld"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6: Compute Term Frequency (TF) for each document\n",
        "def computeTF(wordDict, bagOfWords):\n",
        "    tfDict = {}\n",
        "    bagOfWordsCount = len(bagOfWords)\n",
        "    for word, count in wordDict.items():\n",
        "        tfDict[word] = count / float(bagOfWordsCount)\n",
        "    return tfDict\n",
        "\n",
        "tfA = computeTF(numOfWordsA, bagOfWordsA)\n",
        "tfB = computeTF(numOfWordsB, bagOfWordsB)\n",
        "#Step7 :Compute IDF\n",
        "def computeIDF(documents):\n",
        "    import math\n",
        "    N = len(documents)\n",
        "\n",
        "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
        "    for document in documents:\n",
        "        for word, val in document.items():\n",
        "            if val > 0:\n",
        "                idfDict[word] += 1\n",
        "\n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log(N / float(val))\n",
        "    return idfDict\n",
        "\n",
        "idfs = computeIDF([numOfWordsA, numOfWordsB])\n"
      ],
      "metadata": {
        "id": "wi2IMopaPOLO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 8: Compute TF-IDF for all words\n",
        "#The computeTFIDF function multiplies each term's TF by its IDF.\n",
        "\n",
        "def computeTFIDF(tfBagOfWords, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBagOfWords.items():\n",
        "        tfidf[word] = val * idfs[word]\n",
        "    return tfidf\n",
        "\n",
        "tfidfA = computeTFIDF(tfA, idfs)\n",
        "tfidfB = computeTFIDF(tfB, idfs)\n",
        "import pandas as pd\n",
        "df = pd.DataFrame([tfidfA, tfidfB])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "cjAUwD-cP03w",
        "outputId": "17931e74-327a-499a-fd15-cc83709b6c93"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fourth       Sun   largest   is      from   Jupiter    Planet      Mars  \\\n",
              "0  0.000000  0.000000  0.138629  0.0  0.000000  0.138629  0.138629  0.000000   \n",
              "1  0.086643  0.086643  0.000000  0.0  0.086643  0.000000  0.000000  0.086643   \n",
              "\n",
              "   the    planet  \n",
              "0  0.0  0.000000  \n",
              "1  0.0  0.086643  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c410e79-1a8e-41df-bc6c-8a6c857e4a76\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fourth</th>\n",
              "      <th>Sun</th>\n",
              "      <th>largest</th>\n",
              "      <th>is</th>\n",
              "      <th>from</th>\n",
              "      <th>Jupiter</th>\n",
              "      <th>Planet</th>\n",
              "      <th>Mars</th>\n",
              "      <th>the</th>\n",
              "      <th>planet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138629</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138629</td>\n",
              "      <td>0.138629</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.086643</td>\n",
              "      <td>0.086643</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.086643</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086643</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.086643</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c410e79-1a8e-41df-bc6c-8a6c857e4a76')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c410e79-1a8e-41df-bc6c-8a6c857e4a76 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c410e79-1a8e-41df-bc6c-8a6c857e4a76');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b3c4db24-3470-4b2f-a215-03d1e8d9521e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b3c4db24-3470-4b2f-a215-03d1e8d9521e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b3c4db24-3470-4b2f-a215-03d1e8d9521e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4b83f52c-1f4d-4df4-aaeb-ccab1120b606\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4b83f52c-1f4d-4df4-aaeb-ccab1120b606 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"fourth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061266133966784195,\n        \"min\": 0.0,\n        \"max\": 0.08664339756999316,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.08664339756999316,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sun\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061266133966784195,\n        \"min\": 0.0,\n        \"max\": 0.08664339756999316,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.08664339756999316,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"largest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09802581434685471,\n        \"min\": 0.0,\n        \"max\": 0.13862943611198905,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.13862943611198905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"from\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061266133966784195,\n        \"min\": 0.0,\n        \"max\": 0.08664339756999316,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.08664339756999316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Jupiter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09802581434685471,\n        \"min\": 0.0,\n        \"max\": 0.13862943611198905,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Planet\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09802581434685471,\n        \"min\": 0.0,\n        \"max\": 0.13862943611198905,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mars\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061266133966784195,\n        \"min\": 0.0,\n        \"max\": 0.08664339756999316,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.08664339756999316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"planet\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061266133966784195,\n        \"min\": 0.0,\n        \"max\": 0.08664339756999316,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.08664339756999316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z1kmgMzoQMyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of the Output:\n",
        "Document 0:\n",
        "\n",
        "Words like \"largest,\" \"Jupiter,\" and \"Planet\" have higher TF-IDF scores (0.138629), indicating they are important within this document but do not appear in Document 1.\n",
        "Words that are absent in this document, such as \"fourth,\" \"Sun,\" and \"Mars,\" have scores of 0.\n",
        "Document 1:\n",
        "\n",
        "Words \"fourth,\" \"Sun,\" \"Mars,\" and \"planet\" have non-zero TF-IDF scores (0.086643), showing their importance in Document 1. These words do not appear in Document 0.\n",
        "Words like \"largest,\" \"Jupiter,\" and \"Planet\" have TF-IDF scores of 0, as they are not present in Document 1."
      ],
      "metadata": {
        "id": "3M-hHJyvQgxD"
      }
    }
  ]
}